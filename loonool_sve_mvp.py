from __future__ import annotations
import cv2
import numpy as np
from skimage import feature, color
from dataclasses import dataclass, asdict
import json
# ========= ä¿®å¤ float32 æ— æ³•ä¿å­˜åˆ° JSON çš„é—®é¢˜ =========
import numpy as np
def np_convert(obj):
    """å°† numpy ç±»å‹ï¼ˆfloat32 ç­‰ï¼‰è½¬æ¢ä¸ºæ™®é€š Python ç±»å‹"""
    if isinstance(obj, np.generic):
        return obj.item()
    raise TypeError
import os
from tqdm import tqdm
import mediapipe as mp
import exifread
import matplotlib.pyplot as plt

# ========== LOONOOL Skin Vision Engine v1.0 ==========
# åŠŸèƒ½ï¼šå¯¹ 1~N å¼ è‡ªæ‹ç…§ç‰‡è¿›è¡Œæ ‡å‡†åŒ–ã€åˆ†æã€å¯¹æ¯”ä¸è¶‹åŠ¿è¾“å‡º

@dataclass
class Features:
    brightness_mean: float
    brightness_cv: float
    redness_proxy: float
    yellowness_proxy: float
    texture_entropy: float
    sharpness_lap_var: float
    highfreq_energy: float
    gloss_ratio: float

def read_exif_datetime(path: str) -> str | None:
    try:
        with open(path, 'rb') as f:
            tags = exifread.process_file(f, details=False)
        dt = tags.get('EXIF DateTimeOriginal') or tags.get('Image DateTime')
        return str(dt) if dt else None
    except Exception:
        return None
# ---------- å›¾åƒæ ‡å‡†åŒ– ----------
mp_face = mp.solutions.face_mesh

def align_and_normalize(rgb: np.ndarray) -> np.ndarray:
    """ä½¿ç”¨ Mediapipe å¯¹é½äººè„¸å¹¶æ ‡å‡†åŒ–å…‰ç…§"""
    h, w, _ = rgb.shape
    with mp_face.FaceMesh(static_image_mode=True, max_num_faces=1) as fm:
        res = fm.process(rgb)
        if not res.multi_face_landmarks:
            # æ²¡æ£€æµ‹åˆ°äººè„¸ï¼Œç›´æ¥å±…ä¸­è£å‰ª
            side = min(h, w)
            cx, cy = w // 2, h // 2
            crop = rgb[cy - side//2:cy + side//2, cx - side//2:cx + side//2]
            return cv2.resize(crop, (512, 512))
        lm = res.multi_face_landmarks[0]
        pts = np.array([[p.x * w, p.y * h] for p in lm.landmark], dtype=np.float32)
    # å–ä¸¤çœ¼ä½œä¸ºå¯¹é½åŸºå‡†
    left_eye = pts[[33, 133]].mean(axis=0)
    right_eye = pts[[362, 263]].mean(axis=0)
    dx, dy = right_eye - left_eye
    angle = np.degrees(np.arctan2(dy, dx))
    M = cv2.getRotationMatrix2D(tuple(((left_eye + right_eye) / 2)), angle, 1.0)
    rotated = cv2.warpAffine(rgb, M, (w, h), flags=cv2.INTER_LINEAR)
    # è£å‰ªä¸­å¿ƒåŒºåŸŸ
    side = min(rotated.shape[0], rotated.shape[1])
    cx, cy = rotated.shape[1] // 2, rotated.shape[0] // 2
    crop = rotated[cy - side//2:cy + side//2, cx - side//2:cx + side//2]
    resized = cv2.resize(crop, (512, 512))
    # å…‰ç…§å‡è¡¡ï¼ˆCLAHEï¼‰
    ycrcb = cv2.cvtColor(resized, cv2.COLOR_RGB2YCrCb)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    ycrcb[:, :, 0] = clahe.apply(ycrcb[:, :, 0])
    return cv2.cvtColor(ycrcb, cv2.COLOR_YCrCb2RGB)

# ---------- ç‰¹å¾æå– ----------
def lbp_entropy(gray: np.ndarray) -> float:
    lbp = feature.local_binary_pattern(gray, P=8, R=1, method='uniform')
    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 11), range=(0, 10), density=True)
    hist += 1e-8
    return float(-(hist * np.log(hist)).sum())

def extract_features(rgb: np.ndarray) -> Features:
    lab = color.rgb2lab(rgb / 255.0)
    gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)
    y = cv2.cvtColor(rgb, cv2.COLOR_RGB2YCrCb)[:, :, 0]
    bright_mean = np.mean(y)
    bright_cv = np.std(y) / (np.mean(y) + 1e-6)
    red = np.mean(lab[:, :, 1])
    yellow = np.mean(lab[:, :, 2])
    texture = lbp_entropy(gray)
    sharp = cv2.Laplacian(gray, cv2.CV_64F).var()
    highfreq = np.mean(np.abs(gray.astype(np.float32) - cv2.GaussianBlur(gray, (0, 0), 1)))
    gloss = ((y > 240).sum() / (y.size + 1e-6))
    return Features(bright_mean, bright_cv, red, yellow, texture, sharp, highfreq, gloss)
# ---------- å•å¼ åˆ†æã€å¯¹æ¯”ä¸è¶‹åŠ¿ ----------

def load_rgb(path: str) -> np.ndarray:
    arr = cv2.imdecode(np.fromfile(path, dtype=np.uint8), cv2.IMREAD_COLOR)
    if arr is None:
        raise ValueError(f"æ— æ³•è¯»å–å›¾ç‰‡ï¼š{path}")
    return cv2.cvtColor(arr, cv2.COLOR_BGR2RGB)

def analyze_one(path: str) -> dict:
    rgb = load_rgb(path)
    exif_dt = read_exif_datetime(path)
    rgb_std = align_and_normalize(rgb)
    feats = extract_features(rgb_std)
    return {
        "path": path,
        "exif_datetime": exif_dt,
        "features": asdict(feats)
    }

def pairwise_diff(a: dict, b: dict) -> dict:
    fa, fb = a["features"], b["features"]
    keys = list(fa.keys())
    deltas = {k: float(fb[k] - fa[k]) for k in keys}
    mag = float(np.linalg.norm([deltas[k] for k in keys]))
  # ----- ç½®ä¿¡åº¦è®¡ç®— -----
    try:
        illum = 1 / (1 + abs(fb["brightness_mean"] - fa["brightness_mean"]) / max(1, fa["brightness_mean"]))
        uniform = 1 / (1 + abs(fb["brightness_cv"] - fa["brightness_cv"]) * 100)
        sharp = 1 / (1 + abs(fb["sharpness_lap_var"] - fa["sharpness_lap_var"]) / 500)
        color = 1 / (1 + (abs(fb["redness_proxy"] - fa["redness_proxy"]) +
                          abs(fb["yellowness_proxy"] - fa["yellowness_proxy"])) / 20)
        confidence = round(0.4*illum + 0.2*uniform + 0.3*sharp + 0.1*color, 3)
    except Exception:
        confidence = None

    deltas = {k: float(fb[k] - fa[k]) for k in keys}
    magnitude = float(np.linalg.norm([deltas[k] for k in keys]))
    return {"a": a["path"], "b": b["path"], "deltas": deltas, "magnitude": magnitude, "confidence": confidence}

def trend_summary(all_items: list[dict]) -> dict:
    keys = list(all_items[0]["features"].keys())
    Y = {k: [it["features"][k] for it in all_items] for k in keys}
    idx = np.arange(len(all_items)).astype(np.float32)
    slopes = {}
    for k in keys:
        y = np.array(Y[k], dtype=np.float32)
        x = idx - idx.mean()
        y2 = y - y.mean()
        sxx = (x * x).sum() + 1e-6
        sxy = (x * y2).sum()
        slopes[k] = float(sxy / sxx)
    return {"slopes": slopes, "count": len(all_items)}

# ---------- å¯è§†åŒ–è¾“å‡ºï¼ˆå¯é€‰ HTML + æŠ˜çº¿å›¾ï¼‰ ----------

def render_html(report: dict, out_html: str):
    os.makedirs(os.path.dirname(out_html) or ".", exist_ok=True)
    per = report["per_photo"]
    feats = list(per[0]["features"].keys())
    # é€ç‰¹å¾ç”»è¶‹åŠ¿å›¾
    for feat in feats:
        ys = [p["features"][feat] for p in per]
        plt.figure()
        plt.plot(range(1, len(ys) + 1), ys, marker="o")
        plt.title(f"Trend: {feat}")
        plt.xlabel("Photo index (time)")
        plt.ylabel(feat)
        png_path = out_html.replace(".html", f"_{feat}.png")
        plt.savefig(png_path, bbox_inches="tight")
        plt.close()

    # ç®€å• HTML æ±‡æ€»
    with open(out_html, "w", encoding="utf-8") as f:
        f.write("<html><body>")
        f.write("<h2>LOONOOL Â· Skin Vision Engine Â· MVP</h2>")
        f.write("<p>æœ¬é¡µåŒç›®å½•ä¸‹åŒ…å«æ¯ä¸ªç‰¹å¾çš„è¶‹åŠ¿å›¾ï¼ˆPNGï¼‰ã€‚</p >")
        f.write("<ul>")
        for p in per:
            base = os.path.basename(p["path"])
            dt = p["exif_datetime"] or "-"
            f.write(f"<li>{base} | æ—¶é—´ï¼š{dt}</li>")
        f.write("</ul>")
        f.write("</body></html>")

# ---------- å‘½ä»¤è¡Œå…¥å£ ----------

if __name__ == "__main__":
    import argparse
    ap = argparse.ArgumentParser(description="LOONOOL Skin Vision Engine Â· MVP")
    ap.add_argument("images", nargs="+", help="1~N å¼ å›¾ç‰‡è·¯å¾„ï¼ˆJPG/PNGï¼‰")
    ap.add_argument("--out", default="report.json", help="è¾“å‡º JSON è·¯å¾„")
    ap.add_argument("--html", default=None, help="å¯é€‰ï¼šè¾“å‡º HTML æ±‡æ€»ï¼ˆä¼šç”ŸæˆåŒå PNG å›¾ï¼‰")
    args = ap.parse_args()

    # åˆ†æ
    items = []
    for p in tqdm(args.images, desc="Analyzing"):
        items.append(analyze_one(p))

    # ä¸¤ä¸¤ç›¸é‚»å¯¹æ¯”
    diffs = []
    for i in range(len(items) - 1):
        diffs.append(pairwise_diff(items[i], items[i + 1]))

    # è¶‹åŠ¿
    trend = trend_summary(items) if len(items) >= 3 else None

    report = {
        "per_photo": items,
        "pairwise_diffs": diffs,
        "trend": trend,
        "version": "SVE-MVP v1.0"
    }
    with open(args.out, "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2, default=np_convert)

    if args.html:
        render_html(report, args.html)

    print(f"âœ… å·²ä¿å­˜ JSON æŠ¥å‘Šï¼š{args.out}")
    if args.html:
        print(f"âœ… å·²ç”Ÿæˆ HTMLï¼š{args.html}ï¼ˆåŒç›®å½•åŒ…å«è¶‹åŠ¿ PNG å›¾ï¼‰")
    # -------- ç½®ä¿¡åº¦è‡ªç„¶è¯­è¨€è§£é‡Š --------
    try:
        conf = report["pairwise_diffs"][0].get("confidence", None)
        if conf is not None:
            if conf >= 0.85:
                conf_text = f"ç½®ä¿¡åº¦ {conf:.2f} â†’ å…‰çº¿ä¸è§’åº¦ç¨³å®šï¼Œç»“æœé«˜åº¦å¯ä¿¡ã€‚"
            elif conf >= 0.70:
                conf_text = f"ç½®ä¿¡åº¦ {conf:.2f} â†’ æ‹æ‘„æ¡ä»¶è¾ƒå¥½ï¼Œç»“æœä¸­ç­‰å¯ä¿¡ã€‚"
            else:
                conf_text = f"ç½®ä¿¡åº¦ {conf:.2f} â†’ å…‰ç…§æˆ–è§’åº¦å·®å¼‚è¾ƒå¤§ï¼Œå»ºè®®é‡æ–°æ‹æ‘„ä»¥æé«˜ç²¾åº¦ã€‚"
            print(f"ğŸŒ¤ï¸ {conf_text}")
        else:
            print("æœªæ£€æµ‹åˆ°ç½®ä¿¡åº¦æ•°æ®ã€‚")
    except Exception as e:
        print(f"âš ï¸ æ— æ³•ç”Ÿæˆç½®ä¿¡åº¦è¯´æ˜ï¼š{e}")
# ========= ä¿®å¤ float32 æ— æ³•ä¿å­˜åˆ° JSON çš„é—®é¢˜ =========
import numpy as np
def np_convert(obj):
    """å°† numpy ç±»å‹ï¼ˆfloat32 ç­‰ï¼‰è½¬æ¢ä¸ºæ™®é€š Python ç±»å‹"""
    if isinstance(obj, np.generic):
        return obj.item()
    raise TypeError

# ä¿®æ”¹ä¸»ä¿å­˜é€»è¾‘
if __name__ == "__main__":
    import argparse
    ap = argparse.ArgumentParser(description="LOONOOL Skin Vision Engine Â· MVP")
    ap.add_argument("images", nargs="+", help="1~N å¼ å›¾ç‰‡è·¯å¾„ï¼ˆJPG/PNGï¼‰")
    ap.add_argument("--out", default="report.json", help="è¾“å‡º JSON è·¯å¾„")
    ap.add_argument("--html", default=None, help="è¾“å‡º HTML æŠ¥å‘Š")
    args = ap.parse_args()

    items = []
    for p in args.images:
        items.append(analyze_one(p))

    diffs = []
    for i in range(len(items) - 1):
        diffs.append(pairwise_diff(items[i], items[i + 1]))

    trend = trend_summary(items) if len(items) >= 3 else None

    report = {
        "per_photo": items,
        "pairwise_diffs": diffs,
        "trend": trend,
        "version": "SVE-MVP v1.0"
    }

    with open(args.out, "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2, default=np_convert)

    if args.html:
        render_html(report, args.html)

    print(f"âœ… å·²ä¿å­˜ JSON æŠ¥å‘Šï¼š{args.out}")
    if args.html:
        print(f"âœ… å·²ç”Ÿæˆ HTMLï¼š{args.html}ï¼ˆåŒç›®å½•åŒ…å«è¶‹åŠ¿ PNG å›¾ï¼‰")

import numpy as np
def np_convert(obj):
    if isinstance(obj, np.generic):
        return obj.item()
    raise TypeError

